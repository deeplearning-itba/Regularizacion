{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 7. Inicialización de pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los bias se suelen inicializar en cero\n",
    "- Los 'w's suelen inicializarse de manera aleatoria para romper la simetria entre las unidades ocultas de la misma capa.\n",
    "- La idea general es arrancar en una zona de la función de activación cuya derivada sea significativa.\n",
    "- Los pesos de la salida no son problema.\n",
    "- Se han propuesto varios puntos de partida en diferentes publicaciones\n",
    "\n",
    "Ejemplos para la tangente hiperbolica:  \n",
    "Distribución uniforme entre [-r, r],   \n",
    "donde r es\n",
    "$ r = \\sqrt{\\frac{6}{(fan_{in} + fan_{out})}} $\n",
    "\n",
    "Para sigmoidea:\n",
    "\n",
    "$ r = 4\\sqrt{\\frac{6}{(fan_{in} + fan_{out})}} $\n",
    "\n",
    "También es importonte para redes muy profundas analizar el problema del vanishing y exploting gradient. Se proponen en muchos casos distribuciones gaussianas con:\n",
    "\n",
    "$\\mu = 0$  y $\\sigma^2=\\frac{1}{fan_{in}}$\n",
    "\n",
    "**Recordar que todo esto son puntos de partida y puede ser necesario modificarlos**\n",
    "\n",
    "Referencias: [[1]](https://arxiv.org/pdf/1206.5533.pdf), [[2]](https://www.coursera.org/learn/deep-neural-network/lecture/RwqYe/weight-initialization-for-deep-networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 8. Tamaño del dataset:\n",
    "#### 8.1 Data augmentation\n",
    "#### 8.2 AIC \n",
    "**(Akaike information criterion) [wikipedia](https://en.wikipedia.org/wiki/Akaike_information_criterion)**  \n",
    "$AIC = 2k -2ln(\\hat{L})$ Cantidad de muestras mucho mayor que $k^2$\n",
    "\n",
    "$AICc = AIC + \\frac{2k(k+1)}{n-k-1}$ (with correction)\n",
    "\n",
    "k es la cantidad de parametros, $\\hat{L}$ es el valor máximo del likelihood y n es el tamaño del dataset\n",
    "\n",
    "#### 8.3 BIC \n",
    "**(Bayesian information criterion): [wikipedia](https://en.wikipedia.org/wiki/Bayesian_information_criterion)**  \n",
    "$BIC = ln(n)k - 2ln(\\hat{L})$\n",
    "#### 8.4 DIC \n",
    "**(Deviance information criterion): [wikipedia](https://en.wikipedia.org/wiki/Deviance_information_criterion) [pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.6208&rep=rep1&type=pdf)**  \n",
    "DIC = $log(P(X(i)) - \\frac{1}{(M-1)\\sum{log(P(X(all-but-i)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
